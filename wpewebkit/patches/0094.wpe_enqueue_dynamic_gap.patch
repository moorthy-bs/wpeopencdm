diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index f70bd5ee0..3d9b1c48d 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -99,6 +99,27 @@ namespace WebCore {
 static const double ExponentialMovingAverageCoefficient = 0.1;
 static const bool BufferedLegacyCalcuation = getenv("BUFFERED_LEGACY_CALCULATION") ? true : false;
 
+const auto gEnqueueGapTimerEnabled =
+    nullptr == ::getenv("MSE_ENQUEUE_GAP_TIMER_DISABLE")
+    || std::string{"0"} == ::getenv("MSE_ENQUEUE_GAP_TIMER_DISABLE");
+
+const auto gEnqueueGapTimerInterval =
+    Seconds
+    {
+        nullptr != ::getenv("MSE_ENQUEUE_GAP_TIMER_INTERVAL_MS")
+        ? Seconds::fromMilliseconds(::atoll(::getenv("MSE_ENQUEUE_GAP_TIMER_INTERVAL_MS")))
+        : Seconds::fromMilliseconds(500)
+    };
+
+const MediaTime gEnqueueGapDefault =
+    MediaTime
+    {
+        nullptr != ::getenv("MSE_ENQUEUE_DEFAULT_GAP_MS")
+        ? int64_t(::atoll(getenv("MSE_ENQUEUE_DEFAULT_GAP_MS")))
+        : 100,
+        1000
+    };
+
 struct SourceBuffer::TrackBuffer {
     MediaTime lastDecodeTimestamp;
     MediaTime lastFrameDuration;
@@ -151,6 +172,8 @@ SourceBuffer::SourceBuffer(Ref<SourceBufferPrivate>&& sourceBufferPrivate, Media
     , m_pendingRemoveStart(MediaTime::invalidTime())
     , m_pendingRemoveEnd(MediaTime::invalidTime())
     , m_removeTimer(*this, &SourceBuffer::removeTimerFired)
+    , m_enqueueGapTimer(*this, &SourceBuffer::enqueueGapTimerFired)
+    , m_enqueueGap{gEnqueueGapDefault}
 {
     ASSERT(m_source);
 
@@ -414,6 +437,10 @@ void SourceBuffer::abortIfUpdating()
     if (!m_updating)
         return;
 
+    m_enqueueGapTimer.stop();
+    m_enqueueGap = gEnqueueGapDefault;
+    m_enqueueGapTimerFiredMediaTime = MediaTime::invalidTime();
+
     // 4.1. Abort the buffer append algorithm if it is running.
     m_appendBufferTimer.stop();
     m_pendingAppendData.clear();
@@ -531,6 +558,9 @@ bool SourceBuffer::hasPendingActivity() const
 
 void SourceBuffer::stop()
 {
+    m_enqueueGapTimer.stop();
+    m_enqueueGap = gEnqueueGapDefault;
+    m_enqueueGapTimerFiredMediaTime = MediaTime::invalidTime();
     m_appendBufferTimer.stop();
     m_removeTimer.stop();
 }
@@ -1014,6 +1044,41 @@ void SourceBuffer::removeTimerFired()
     scheduleEvent(eventNames().updateendEvent);
 }
 
+void SourceBuffer::enqueueGapTimerFired()
+{
+    if(isRemoved()) return;
+
+    const auto currentMediaTime = m_source->currentTime();
+    const auto paused = m_source->mediaElement()->paused();
+
+    if(
+        !paused
+        && m_enqueueGapTimerFiredMediaTime.isValid()
+        && m_enqueueGapTimerFiredMediaTime == currentMediaTime)
+    {
+        /* if playback is not progressing increase the gap */
+        m_enqueueGap =
+            MediaTime{m_enqueueGap.timeValue() << 1, m_enqueueGap.timeScale()};
+    }
+
+    m_enqueueGapTimerFiredMediaTime = currentMediaTime;
+
+    LOG(
+        MediaSource,
+        "%p %fs paused %d enqueueGapTimerFiredMediaTime %fs enqueueGap %fs",
+        this,
+        MediaTime{g_get_monotonic_time(), GST_USECOND}.toDouble(),
+        paused,
+        m_enqueueGapTimerFiredMediaTime.toDouble(),
+        m_enqueueGap.toDouble());
+
+    for(auto &i : m_trackBufferMap)
+    {
+        if(i.value.needsReenqueueing) reenqueueMediaForTime(i.value, i.key, currentMediaTime);
+        else provideMediaData(i.value, i.key);
+    }
+}
+
 void SourceBuffer::evictRangeIfPossible(const MediaTime &begin, const MediaTime &end)
 {
     const auto currTime = m_source->currentTime();
@@ -2255,27 +2320,29 @@ void SourceBuffer::provideMediaData(TrackBuffer& trackBuffer, const AtomicString
 
     LOG(
         MediaSource,
-        "(%p) "
+        "%p "
         "%s "
         "HPTS %fs "
         "LDT %fs "
+        "LFD %fs "
         "LEPTS %fs "
         "LEDET %fs "
+        "enqueueGap %fs "
         "buffered %s",
         this,
         trackID.string().utf8().data(),
         trackBuffer.highestPresentationTimestamp.toDouble(),
         trackBuffer.lastDecodeTimestamp.toDouble(),
+        trackBuffer.lastFrameDuration.toDouble(),
         trackBuffer.lastEnqueuedPresentationTime.toDouble(),
         trackBuffer.lastEnqueuedDecodeEndTime.toDouble(),
+        m_enqueueGap.toDouble(),
         toString(m_buffered->ranges()).utf8().data());
 
 
 #if !LOG_DISABLED
     unsigned enqueuedSamples = 0;
 #endif
-    MediaTime lastEnqueuedPresentationTime = MediaTime::invalidTime();
-    MediaTime lastEnqueuedDecodeEndTime = MediaTime::invalidTime();
     const auto currTime = m_source->currentTime();
 
     while (!trackBuffer.decodeQueue.empty()) {
@@ -2284,10 +2351,17 @@ void SourceBuffer::provideMediaData(TrackBuffer& trackBuffer, const AtomicString
 
             LOG(
                 MediaSource,
-                "(%p) trackID %s not ready for more samples",
+                "%p %s not ready for more samples",
                 this,
                 trackID.string().utf8().data());
 
+            if(m_enqueueGapTimer.isActive())
+            {
+                m_enqueueGapTimer.stop();
+                m_enqueueGap = gEnqueueGapDefault;
+                m_enqueueGapTimerFiredMediaTime = MediaTime::invalidTime();
+            }
+
             break;
         }
 
@@ -2296,33 +2370,44 @@ void SourceBuffer::provideMediaData(TrackBuffer& trackBuffer, const AtomicString
         // rather than when all samples have been enqueued.
         auto sample = trackBuffer.decodeQueue.begin()->second;
 
-        // Do not enqueue samples spanning a significant unbuffered gap.
-        // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run
-        // on the playbackTimer, which is effectively every 350ms. Allowing > 350ms gap between
-        // enqueued samples allows for situations where we overrun the end of a buffered range
-        // but don't notice for 350s of playback time, and the client can enqueue data for the
-        // new current time without triggering this early return.
-        // FIXME(135867): Make this gap detection logic less arbitrary.
-        MediaTime threshold(200, 1000);  // 200ms
-
-        if (
+        if(
             trackBuffer.lastEnqueuedPresentationTime.isValid()
-            && sample->presentationTime() - trackBuffer.lastEnqueuedPresentationTime > threshold)
+            && trackBuffer.lastFrameDuration.isValid())
         {
-            LOG(
-                MediaSource,
-                "(%p) track %s LEPTS %fs",
-                this,
-                trackID.string().utf8().data(),
-                trackBuffer.lastEnqueuedPresentationTime.toDouble());
-            break;
+            const auto gap =
+                sample->presentationTime()
+                -(trackBuffer.lastEnqueuedPresentationTime + trackBuffer.lastFrameDuration);
+
+            if(gap > m_enqueueGap)
+            {
+                LOG(
+                        MediaSource,
+                        "%p %s LFD %fs LEPTS %fs enqueueGap %fs gap %fs",
+                        this,
+                        trackID.string().utf8().data(),
+                        trackBuffer.lastFrameDuration.toDouble(),
+                        trackBuffer.lastEnqueuedPresentationTime.toDouble(),
+                        m_enqueueGap.toDouble(),
+                        gap.toDouble());
+
+                if(gEnqueueGapTimerEnabled && !m_enqueueGapTimer.isActive())
+                {
+                    m_enqueueGapTimer.startRepeating(gEnqueueGapTimerInterval);
+                }
+                break;
+            }
+        }
+
+        if(m_enqueueGapTimer.isActive())
+        {
+            m_enqueueGapTimer.stop();
+            m_enqueueGapTimerFiredMediaTime = MediaTime::invalidTime();
         }
 
         trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin());
+        trackBuffer.lastFrameDuration = sample->duration();
         trackBuffer.lastEnqueuedPresentationTime = sample->presentationTime();
         trackBuffer.lastEnqueuedDecodeEndTime = sample->decodeTime() + sample->duration();
-        lastEnqueuedPresentationTime = sample->presentationTime();
-        lastEnqueuedDecodeEndTime =sample->decodeTime() + sample->duration();
 
         LOG(
             MediaSource,
@@ -2378,6 +2463,7 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, const AtomicS
         "HPTS %fs "
         "LEPTS %fs "
         "LEDET %fs  "
+        "LFD %fs "
         "buffered %s",
         this, time.toDouble(),
         trackID.string().utf8().data(),
@@ -2385,6 +2471,7 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, const AtomicS
         trackBuffer.highestPresentationTimestamp.toDouble(),
         trackBuffer.lastEnqueuedPresentationTime.toDouble(),
         trackBuffer.lastEnqueuedDecodeEndTime.toDouble(),
+        trackBuffer.lastFrameDuration.toDouble(),
         toString(m_buffered->ranges()).utf8().data());
 
     const MediaTime currentMediaTime = m_source->currentTime();
@@ -2438,9 +2525,11 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, const AtomicS
 
     if (!trackBuffer.decodeQueue.empty()) {
         auto& lastSample = trackBuffer.decodeQueue.rbegin()->second;
+        trackBuffer.lastFrameDuration = lastSample->duration();
         trackBuffer.lastEnqueuedPresentationTime = lastSample->presentationTime();
         trackBuffer.lastEnqueuedDecodeEndTime = lastSample->decodeTime() + lastSample->duration();
     } else {
+        trackBuffer.lastFrameDuration = MediaTime::invalidTime();
         trackBuffer.lastEnqueuedPresentationTime = MediaTime::invalidTime();
         trackBuffer.lastEnqueuedDecodeEndTime = MediaTime::invalidTime();
     }
@@ -2454,6 +2543,7 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, const AtomicS
         "HPTS %fs "
         "LEPTS %fs "
         "LEDET %fs "
+        "LFD %fs "
         "buffered %s",
         this,
         time.toDouble(),
@@ -2462,6 +2552,7 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, const AtomicS
         trackBuffer.highestPresentationTimestamp.toDouble(),
         trackBuffer.lastEnqueuedPresentationTime.toDouble(),
         trackBuffer.lastEnqueuedDecodeEndTime.toDouble(),
+        trackBuffer.lastFrameDuration.toDouble(),
         toString(m_buffered->ranges()).utf8().data());
 
     // Fill the decode queue with the remaining samples.
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index 8da4cd1c1..dc03c9d55 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -170,6 +170,7 @@ private:
     void monitorBufferingRate();
 
     void removeTimerFired();
+    void enqueueGapTimerFired();
     void removeCodedFrames(const MediaTime& start, const MediaTime& end, bool);
 
     size_t extraMemoryCost() const;
@@ -234,6 +235,10 @@ private:
     static size_t maxBufferSizeVideo;
     static size_t maxBufferSizeAudio;
     static size_t maxBufferSizeText;
+
+    Timer m_enqueueGapTimer;
+    MediaTime m_enqueueGap;
+    MediaTime m_enqueueGapTimerFiredMediaTime = MediaTime::invalidTime();
 };
 
 } // namespace WebCore
